# Next Steps: Comprehensive UK Public Service Discovery

**Feature**: 002-add-9500-public-services
**Date**: 2025-10-26
**Status**: Proof-of-Concept Complete, Full-Scale Data Collection Pending
**Document Version**: 3.0

---

## Executive Summary

### What's Done

**Infrastructure Status**: ‚úÖ **PRODUCTION-READY**

All technical infrastructure has been implemented, tested, and successfully deployed:

- **Validation Pipeline**: 9 validation scripts operational (100% success rate)
- **Taxonomy System**: 74 tags across 6 dimensions defined and working
- **Proof-of-Concept**: 23 government services validated and merged into config.yaml
- **Production Deployment**: Config.yaml now contains 205 total services (was 182)
- **Quality Assurance**: JSON Schema validation passing, 95.83% pipeline success rate
- **Task Completion**: 29/172 tasks complete (16.86%) - all foundational infrastructure done

### What Remains

**Data Collection Phase**: ‚è≥ **READY TO BEGIN**

The remaining work is **manual research and service discovery**:

- **153 tasks** (89% of total) - primarily service discovery and validation
- **9 user stories** requiring exhaustive research across UK public services
- **Estimated effort**: 80-120 hours of manual research work
- **Target**: 9500+ unique service endpoints (currently have 23 proof-of-concept)

### Time Estimates

**Sequential execution** (single researcher):
- Option 1 (Proof-of-Concept): ‚úÖ **COMPLETE** (30 minutes)
- Option 2 (P1 User Stories): 25-35 hours (3-5 days)
- Option 3 (Full MVP): 60-80 hours (8-10 days)
- Option 4 (Complete 9500+): 80-120 hours (10-15 days)

**Parallel execution** (5-person team):
- Foundational setup: 0.5 days (shared)
- User Stories 1-7: 2.5 days (parallel)
- Documentation phase: 1 day
- **Total**: 6-7 working days

---

## Implementation Options

### Option 1: Proof-of-Concept (Sample Data) ‚úÖ COMPLETE

**Status**: ‚úÖ **SUCCESSFULLY DEPLOYED**

**What was delivered**:
- 23 government services validated through complete pipeline
- All 9 validation scripts tested and proven operational
- Config.yaml successfully merged (182 ‚Üí 205 services)
- JSON Schema validation passing
- 95.83% pipeline success rate demonstrated

**Time spent**: 30 minutes

**Outcome**: Technical infrastructure proven end-to-end, ready for full-scale data collection

**Next action**: Choose Option 2, 3, or 4 for data collection phase

---

### Option 2: P1 User Stories Only (Recommended for MVP)

**Target**: 2500-3800 services across critical government functions

**Scope**: Priority 1 user stories (most critical services):
- **US1**: Government Services (HMRC, DVLA, DWP, Home Office, MOJ, DfE, DEFRA, Companies House)
- **US2**: NHS Services (all 4 UK health systems)
- **US3**: Emergency Services (police, fire, ambulance, coast guard)

**Effort estimate**: 25-35 hours

**Task breakdown**:
- US1 (Government Services): 10-15 hours
  - T020-T030: Discovery (DNS, CT logs, web search) - 8-12 hours
  - T031-T041: Validation pipeline - 2-3 hours (automated)
- US2 (NHS Services): 8-12 hours
  - T042-T050: Discovery across 4 health systems - 6-9 hours
  - T051-T061: Validation pipeline - 2-3 hours (automated)
- US3 (Emergency Services): 4-6 hours
  - T062-T068: Discovery (police, fire, ambulance) - 3-4 hours
  - T069-T079: Validation pipeline - 1-2 hours (automated)
- Final integration: 3-4 hours

**Timeline**: 3-5 working days (single researcher), 1.5-2 days (team of 3)

**Why recommended**:
- Delivers high-value critical services first
- Achieves minimum viable product status
- Demonstrates comprehensive monitoring capability
- Manageable scope with clear deliverables
- Can be extended incrementally to Option 3 or 4

**Success criteria met**:
- SC-002: 50+ services per major department ‚úì
- SC-003: All 4 UK health systems ‚úì
- SC-004: 100+ emergency service endpoints ‚úì
- SC-008-SC-013: Infrastructure criteria ‚úì

---

### Option 3: Full MVP (US1-US7)

**Target**: 6000-8000 services across all categories

**Scope**: All priority 1-2 user stories:
- **P1**: US1-US3 (as per Option 2)
- **P2**: US4 (Local Government), US5 (Third-Party), US6 (*.services.gov.uk), US7 (Justice)

**Effort estimate**: 60-80 hours

**Additional effort beyond Option 2**:
- US4 (Local Government): 6-8 hours
- US5 (Third-Party Services): 4-6 hours
- US6 (*.services.gov.uk Discovery): 15-20 hours (comprehensive DNS enumeration)
- US7 (Justice Services): 6-8 hours
- Final integration: 4 hours

**Timeline**: 8-10 working days (single researcher), 3-4 days (team of 5)

**Why choose this**:
- Near-complete coverage of UK public services
- Likely meets 9500+ target through *.services.gov.uk discovery
- Comprehensive service catalog
- Strong foundation for ongoing monitoring

**Success criteria met**: SC-001 through SC-013 (likely all criteria)

---

### Option 4: Complete Feature (All User Stories)

**Target**: 9500+ services (exhaustive discovery)

**Scope**: All user stories US1-US9 including documentation

**Effort estimate**: 80-120 hours

**Full breakdown**:
- Phase 1-2 (Infrastructure): ‚úÖ COMPLETE
- Phase 3 (US1 - Government): 10-15 hours
- Phase 4 (US2 - NHS): 8-12 hours
- Phase 5 (US3 - Emergency): 4-6 hours
- Phase 6 (US4 - Local Gov): 6-8 hours
- Phase 7 (US5 - Third-Party): 4-6 hours
- Phase 8 (US6 - *.services.gov.uk): 15-20 hours
- Phase 9 (US7 - Justice): 6-8 hours
- Phase 10 (US8 - Taxonomy Refinement): 4 hours
- Phase 11 (US9 - Documentation): 4 hours
- Phase 12 (Final Integration): 4 hours

**Timeline**: 10-15 working days (single researcher), 6-7 days (team of 5)

**Why choose this**:
- Complete feature specification delivered
- Exhaustive service coverage
- Comprehensive documentation for maintainability
- Full taxonomy implementation
- Sets standard for ongoing service discovery

**Success criteria met**: All SC-001 through SC-013

---

## Recommended Approach: Option 2 (P1 User Stories)

**Rationale**:

Option 2 provides the optimal balance of value delivery and resource investment:

1. **High Impact**: Critical services (government, NHS, emergency) deliver maximum monitoring value
2. **Manageable Scope**: 25-35 hours is achievable within a single sprint
3. **Incremental Path**: Can extend to Option 3/4 based on results
4. **Risk Mitigation**: Proves data collection process at scale before committing to full 9500+
5. **Fast Time-to-Value**: 3-5 days to production-quality monitoring expansion

**Success metrics**:
- 2500-3800 services discovered and validated
- 50+ services per major government department
- All 4 UK health systems covered
- 100+ emergency service endpoints
- 95%+ validation success rate (proven in POC)
- Zero JSON Schema validation errors

---

## Execution Strategy

### Parallelization Opportunities

The task structure supports significant parallelization:

**Within a single user story** (e.g., US1 - Government Services):
```bash
# All discovery tasks can run in parallel:
T020: DNS enumeration *.services.gov.uk (subfinder)
T021: Certificate Transparency query (crt.sh)
T022: DNS enumeration *.gov.uk (amass - 20+ min)
T023: Web search HMRC services
T024: Web search DVLA services
T025: Web search DWP services
T026: Web search Home Office services
T027: Web search MOJ services
T028: Web search DfE services
T029: Web search DEFRA services
T030: Web search Companies House/IPO

# Run 11 discovery tasks concurrently
# Time: 20-30 minutes vs 3+ hours sequential
```

**Across multiple user stories**:
```bash
# After infrastructure complete, parallel execution:
Researcher A: User Story 1 (Government - 10-15 hours)
Researcher B: User Story 2 (NHS - 8-12 hours)
Researcher C: User Story 3 (Emergency - 4-6 hours)

# 3-day team effort vs 5-day solo effort
```

**Validation pipeline** (automated after discovery):
```bash
# Sequential pipeline per user story (automated):
T032: URL normalization (1 min per 100 services)
T033: Redirect resolution (2 min per 100 services)
T034: Deduplication (instant)
T035: Accessibility validation (3 min per 100 services)
T036: Tag application (instant)
T037: Transform to entries (instant)
T038: Group by category (instant)
T039: Generate YAML (instant)
T040: Validate schema (instant)
T041: Generate report (instant)

# Total pipeline: ~5 min per 100 services
```

### Team Structure Options

**Option A: Solo researcher** (3-5 days for P1 stories)
- Day 1: Complete US1 discovery (T020-T030), run validation pipeline
- Day 2: Complete US1 validation review, start US2 discovery
- Day 3: Complete US2, start US3
- Day 4: Complete US3, final integration
- Day 5: Quality review and merge

**Option B: 3-person team** (1.5-2 days for P1 stories)
- Day 1 AM: Researcher A (US1), B (US2), C (US3) - parallel discovery
- Day 1 PM: All run validation pipelines in parallel
- Day 2: Validation review, integration, quality checks, merge

**Option C: 5-person team** (1 day for P1 stories)
- Hours 1-4: Parallel discovery (US1, US2, US3 split by sub-tasks)
- Hours 5-6: Validation pipelines
- Hours 7-8: Integration and quality review

### Quality Gates

**Gate 1: Discovery completeness** (before validation)
- Minimum service counts per user story met
- All discovery methods executed (DNS, CT logs, web search, manual review)
- Discovery sources documented

**Gate 2: Validation success rate** (after automated pipeline)
- 90%+ accessibility validation pass rate (proven: 95.83% in POC)
- All accessible services have appropriate tags
- No duplicate services (canonical URL deduplication working)

**Gate 3: YAML quality** (before config.yaml merge)
- JSON Schema validation passes (zero errors)
- YAML file size under 5MB
- Comments and organization clear
- Manual spot-check of 20 random services

**Gate 4: Integration testing** (before branch merge)
- Config.yaml validates with new services
- Test run of monitoring system completes without errors
- No resource exhaustion (CPU, memory, network)
- Coverage report confirms success criteria met

---

## Discovery Method Guide

### When to Use Each Discovery Method

**DNS Enumeration** (Subfinder):
- **Use for**: Discovering *.services.gov.uk, *.nhs.uk subdomains
- **Time**: 30-60 seconds per domain
- **Coverage**: Active subdomains with DNS records
- **Command**:
  ```bash
  subfinder -d services.gov.uk -o research-data/discovered/services-gov-uk.txt
  ```
- **Best for**: US1, US2, US6

**DNS Enumeration** (Amass):
- **Use for**: Comprehensive passive discovery (20+ sources)
- **Time**: 20+ minutes per domain
- **Coverage**: Historical and active subdomains
- **Command**:
  ```bash
  amass enum -passive -d gov.uk -o research-data/discovered/gov-uk-amass.txt
  ```
- **Best for**: US1, US6 (when exhaustive coverage needed)

**Certificate Transparency Logs** (crt.sh):
- **Use for**: Discovering services from TLS certificates
- **Time**: 2-5 minutes per domain pattern
- **Coverage**: Any service that's ever had a TLS certificate
- **Command**:
  ```bash
  curl "https://crt.sh/?q=%.services.gov.uk&output=json" | jq -r '.[].name_value' | sort -u
  ```
- **Best for**: US1, US6

**Web Search Discovery**:
- **Use for**: Finding services by function/department
- **Time**: 10-30 minutes per department
- **Coverage**: Public-facing services with web presence
- **Examples**:
  ```
  site:*.service.gov.uk hmrc OR tax
  site:*.nhs.uk appointment OR booking
  site:*.police.uk report OR online
  ```
- **Best for**: US1, US2, US3, US4, US5, US7

**Government Directory Reviews**:
- **Use for**: Official service catalogs and listings
- **Time**: 15-45 minutes per directory
- **Coverage**: Officially documented services
- **Examples**:
  - GOV.UK service directory
  - NHS Digital service catalog
  - Police.UK force directory
  - Local authority service lists
- **Best for**: All user stories (validation and gap filling)

**Manual Department Reviews**:
- **Use for**: Department-specific service pages
- **Time**: 30-60 minutes per major department
- **Coverage**: Department-published service links
- **Best for**: US1, US4, US7 (comprehensive departmental coverage)

### Discovery Method by User Story

| User Story | Primary Methods | Secondary Methods | Est. Time |
|------------|----------------|-------------------|-----------|
| US1 (Government) | DNS enum, Web search | CT logs, Gov directories | 10-15h |
| US2 (NHS) | DNS enum, Web search | NHS Digital catalog | 8-12h |
| US3 (Emergency) | Web search, Manual review | Police.UK directory | 4-6h |
| US4 (Local Gov) | Web search, Gov directories | Local authority sampling | 6-8h |
| US5 (Third-Party) | Web search, Procurement data | Digital Marketplace | 4-6h |
| US6 (*.services.gov.uk) | DNS enum, CT logs | Web search validation | 15-20h |
| US7 (Justice) | Web search, HMCTS directory | Manual review | 6-8h |

---

## Success Criteria Tracking

### Infrastructure-Related (Already Met) ‚úÖ

**SC-008**: No resource exhaustion
- **Status**: ‚úÖ Met (validated with 205 services)
- **Evidence**: Config.yaml passes validation, monitoring system operational
- **Next phase**: Will validate at 500, 1000, 2500, 5000, 9500+ service milestones

**SC-009**: Zero schema errors
- **Status**: ‚úÖ Met (sample YAML validates perfectly)
- **Evidence**: JSON Schema validation passing on all generated YAML
- **Process**: Automated validation in T040, T060, T078, T094, T110, T125, T140

**SC-011**: Documented methodology
- **Status**: ‚úÖ Met (quickstart.md, research.md complete)
- **Evidence**: Full research methodology documented with reproducible steps
- **Maintained**: US9 will generate additional documentation reports

**SC-012**: 50+ unique tags
- **Status**: ‚úÖ Met (74 tags defined and operational)
- **Evidence**: taxonomy.json contains 74 tags across 6 dimensions
- **Validation**: Tag application proven in POC (T036 complete)

### Data Collection-Related (Pending) ‚è≥

**SC-001**: 9500+ services
- **Status**: ‚è≥ Pending (currently 205 services, 23 from this feature)
- **Target**: 9500+ unique endpoints
- **Progress tracking**:
  - Option 1: 23 services (0.2% of target)
  - Option 2: 2500-3800 services (26-40% of target)
  - Option 3: 6000-8000 services (63-84% of target)
  - Option 4: 9500+ services (100% of target)

**SC-002**: 50+ per major department
- **Status**: ‚è≥ Pending (7 departments represented, <10 per dept)
- **Target**: HMRC, DVLA, DWP, NHS, Home Office, MOJ (50+ each)
- **Achieved in**: Option 2 (US1 targets 50+ per major dept)

**SC-003**: 4 UK health systems
- **Status**: ‚è≥ Pending (NHS England represented only)
- **Target**: NHS England, Scotland, Wales, Northern Ireland
- **Achieved in**: Option 2 (US2 discovers all 4 systems)

**SC-004**: 100+ emergency services
- **Status**: ‚è≥ Pending (0 emergency services)
- **Target**: Police, fire, ambulance, coast guard (100+ endpoints)
- **Achieved in**: Option 2 (US3 targets 100+ emergency endpoints)

**SC-005**: 200+ local government
- **Status**: ‚è≥ Pending (0 local government services)
- **Target**: Shared platforms + council-specific (200+ endpoints)
- **Achieved in**: Option 3 (US4)

**SC-006**: 50+ *.services.gov.uk subdomains
- **Status**: ‚è≥ Pending (estimated 10-15 currently)
- **Target**: 50+ unique subdomains
- **Achieved in**: Option 3 (US6 comprehensive DNS enumeration)

**SC-007**: 100+ third-party services
- **Status**: ‚è≥ Pending (0 third-party services)
- **Target**: Booking, payment, contracted platforms (100+ endpoints)
- **Achieved in**: Option 3 (US5)

### Post-Deployment Criteria (Future) üîÆ

**SC-010**: 15min monitoring cycle
- **Status**: üîÆ Post-deployment testing
- **Verification**: Monitor deployment logs after config.yaml merge

**SC-013**: Page load < 2s
- **Status**: üîÆ Post-deployment testing
- **Verification**: Browser performance testing after status page generation

---

## Risk Mitigation

### Risk 1: Discovery Incompleteness

**Risk**: Manual research may miss significant service categories

**Mitigation**:
- Use multiple discovery methods per user story (DNS + CT logs + web search + directories)
- Cross-reference with official government service catalogs
- Peer review of discovered services (spot-check coverage)
- Breadth-first strategy ensures minimum baseline across all categories
- Document excluded services with reasons (US9)

**Detection**: Coverage report (T041, T061, T079, etc.) flags departments below minimum thresholds

**Recovery**: Targeted deep-dive search for under-represented categories

---

### Risk 2: Validation Failure Rate

**Risk**: High percentage of discovered URLs may fail accessibility validation

**Mitigation**:
- POC demonstrated 95.83% success rate (acceptable baseline)
- Retry logic handles transient network failures (3 attempts)
- Follow redirects to canonical URLs before validation
- Expected status codes handle auth-protected services (401/403)
- Manual review of failed services to identify internal-only vs configuration issues

**Detection**: Validation pipeline reports (T035, T055, T073, etc.) show pass/fail rates

**Recovery**: Adjust expected status codes, add custom headers, or exclude truly internal services

---

### Risk 3: Config.yaml Size and Maintainability

**Risk**: 9500+ service entries may create unmaintainable YAML file

**Mitigation**:
- Programmatic YAML generation with comments and section organization (T039, T059, etc.)
- Category grouping by criticality tier and department
- YAML size monitoring (target: <5MB per SC assumption)
- Automated validation prevents syntax errors (T040, T060, T078, etc.)
- Documentation of organizational structure in inline comments

**Detection**: T166 validates file size under 5MB, manual review in T168

**Recovery**: Split into multiple YAML files if needed (requires monitoring system update)

---

### Risk 4: Time Estimation Accuracy

**Risk**: Manual research may take longer than estimated 80-120 hours

**Mitigation**:
- Incremental delivery options (Option 2 ‚Üí 3 ‚Üí 4)
- Parallel execution reduces calendar time
- Automated validation pipeline proven operational (5min per 100 services)
- Stop at any checkpoint if time constraints require
- POC proves infrastructure works, reducing rework risk

**Detection**: Track actual time per user story, compare to estimates

**Recovery**: Scope reduction to Option 2 or 3 if needed, defer US8/US9 documentation

---

### Risk 5: Discovery Method Failure

**Risk**: DNS enumeration or web search tools may fail or be rate-limited

**Mitigation**:
- Multiple discovery methods per user story (redundancy)
- Both Subfinder and Amass for DNS (two independent tools)
- CT logs as backup to DNS enumeration
- Manual directory review validates automated discovery
- Rate limiting via API keys (Censys, VirusTotal free tiers)

**Detection**: Empty or suspiciously small discovery result files

**Recovery**: Retry with different tools, use alternative API sources, increase manual review proportion

---

## Getting Started: Day-by-Day Action Plan

### Option 2 (P1 User Stories) - Solo Researcher

**Day 1: User Story 1 (Government Services)**

*Morning (4 hours)*:
```bash
# Launch parallel discovery tasks
cd /Users/cns/httpdocs/cddo/status

# T020: DNS enumeration *.services.gov.uk (1 min)
subfinder -d services.gov.uk -o specs/002-add-9500-public-services/research-data/discovered/services-gov-uk.txt

# T021: CT logs query (2 min)
curl "https://crt.sh/?q=%.services.gov.uk&output=json" | \
  jq -r '.[].name_value' | sort -u > specs/002-add-9500-public-services/research-data/discovered/services-gov-uk-crtsh.txt

# T022: Amass comprehensive scan (20+ min - run in background)
amass enum -passive -d gov.uk -o specs/002-add-9500-public-services/research-data/discovered/gov-uk-amass.txt &

# While Amass runs, do web search discovery (T023-T030):
# - Use WebSearch tool for "site:*.service.gov.uk hmrc OR tax"
# - Extract URLs to JSON files
# - Target: 50+ HMRC, 50+ DVLA, 50+ DWP, 50+ Home Office, 30+ MOJ, 30+ DfE, 30+ DEFRA, 20+ Companies House
# - Time: 3 hours manual research and extraction
```

*Afternoon (4 hours)*:
```bash
# T031: Merge all discovery sources
cat specs/002-add-9500-public-services/research-data/discovered/services-gov-uk.txt \
    specs/002-add-9500-public-services/research-data/discovered/services-gov-uk-crtsh.txt \
    specs/002-add-9500-public-services/research-data/discovered/gov-uk-amass.txt | \
  sort -u > specs/002-add-9500-public-services/research-data/discovered/government-services-all.txt

# Run validation pipeline (T032-T041) - automated, ~5min per 100 services
pnpm exec tsx scripts/normalize-urls.ts government-services-all.txt
pnpm exec tsx scripts/resolve-redirects.ts government-services-normalized.json
pnpm exec tsx scripts/deduplicate.ts government-services-canonical.json
pnpm exec tsx scripts/validate-accessibility.ts government-services-unique.json
pnpm exec tsx scripts/apply-tags.ts government-services-validated.json
pnpm exec tsx scripts/transform-to-entries.ts government-services-tagged.json
pnpm exec tsx scripts/generate-yaml.ts government-service-entries.json
pnpm exec tsx scripts/validate-config.ts research-data/government-services.yaml
pnpm exec tsx scripts/generate-report.ts government-service-entries.json

# Review coverage report, verify 50+ per major dept (SC-002)
# Manual review of generated YAML (spot-check 20 random services)
```

**Day 2: User Story 2 (NHS Services)**

*Morning (4 hours)*:
```bash
# T042-T046: DNS enumeration for NHS domains (parallel)
subfinder -d nhs.uk -o research-data/discovered/nhs-england.txt &
subfinder -d scot.nhs.uk -o research-data/discovered/nhs-scotland.txt &
subfinder -d nhs.wales -o research-data/discovered/nhs-wales.txt &
subfinder -d hscni.net -o research-data/discovered/nhs-ni.txt &

# T046: CT logs for NHS
curl "https://crt.sh/?q=%.nhs.uk&output=json" | \
  jq -r '.[].name_value' | sort -u > research-data/discovered/nhs-uk-crtsh.txt

# T047-T049: Web search discovery (while DNS runs)
# - "site:*.nhs.uk 111 OR urgent"
# - "site:*.nhs.uk book OR appointment"
# - "site:*.nhs.uk app OR digital"
# - Time: 3 hours manual research
```

*Afternoon (4 hours)*:
```bash
# T050: Manual NHS Digital catalog review
# - https://digital.nhs.uk/services
# - Extract service URLs

# T051-T061: Merge and run validation pipeline
# - Same process as US1
# - Verify coverage across all 4 health systems (SC-003)
```

**Day 3: User Story 3 (Emergency Services)**

*Morning (3 hours)*:
```bash
# T062-T068: Discovery (mix of DNS, web search, manual review)
subfinder -d police.uk -o research-data/discovered/police-uk.txt

# Web searches:
# - "site:*.police.uk report OR crime"
# - "site:*.fire.uk OR site:*.fireservice.co.uk"
# - "site:*.ambulance.nhs.uk"
# - "site:*.mcga.gov.uk OR site:*.rnli.org.uk"
# - Manual review of Police.UK force list
# - Time: 3 hours
```

*Afternoon (3 hours)*:
```bash
# T069-T079: Merge and validation pipeline
# - Verify 100+ emergency endpoints (SC-004)
# - Focus on critical services (60-second check intervals)
```

**Day 4: Final Integration**

*Full day (8 hours)*:
```bash
# T156-T172: Final integration tasks
# - Merge all user story YAML files
# - Validate against success criteria
# - Manual quality review
# - Backup config.yaml
# - Merge new services
# - Final validation
# - Commit to branch

# Success criteria verification:
# - SC-002: 50+ per major dept ‚úì
# - SC-003: All 4 health systems ‚úì
# - SC-004: 100+ emergency ‚úì
# - SC-008: No resource exhaustion ‚úì
# - SC-009: Zero schema errors ‚úì

# Estimated total services: 2500-3800
```

**Day 5: Quality Review and Documentation**

*Half day (4 hours)*:
```bash
# Final quality checks
# - Test run monitoring system
# - Performance validation
# - Generate coverage reports
# - Update IMPLEMENTATION_STATUS.md
# - Update tasks.md completion status
# - Prepare PR description

# Ready for branch merge or PR to main
```

---

### Option 2 (P1 User Stories) - 3-Person Team

**Day 1 Morning (4 hours) - Parallel Discovery**

Researcher A (US1 - Government):
```bash
# All T020-T030 discovery tasks in parallel
# Target: 400+ government services discovered
```

Researcher B (US2 - NHS):
```bash
# All T042-T050 discovery tasks in parallel
# Target: 200+ NHS services discovered
```

Researcher C (US3 - Emergency):
```bash
# All T062-T068 discovery tasks in parallel
# Target: 100+ emergency services discovered
```

**Day 1 Afternoon (4 hours) - Validation Pipelines**

All researchers run validation pipelines in parallel:
```bash
# Each researcher runs T0XX-T0XX validation for their user story
# Automated process, ~5min per 100 services
# Remainder: manual spot-checking and review
```

**Day 2 (8 hours) - Integration and Quality**

All researchers together:
```bash
# Morning: Final integration (T156-T172)
# Afternoon: Quality review, testing, documentation
# Ready for merge by EOD
```

**Total calendar time**: 1.5-2 days for 2500-3800 services

---

## Resources and Documentation

### File Locations

**Specification documents**:
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/spec.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/plan.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/research.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/data-model.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/quickstart.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/tasks.md`

**Implementation tracking**:
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/IMPLEMENTATION_STATUS.md`
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/NEXT-STEPS.md` (this document)

**Validation scripts** (all operational):
- `/Users/cns/httpdocs/cddo/status/scripts/normalize-urls.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/resolve-redirects.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/deduplicate.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/validate-accessibility.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/apply-tags.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/transform-to-entries.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/generate-yaml.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/validate-config.ts`
- `/Users/cns/httpdocs/cddo/status/scripts/generate-report.ts`

**Research data directory**:
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/research-data/`
  - `discovered/` - Raw discovery outputs (DNS, CT logs, web search)
  - `validated/` - Validation pipeline intermediate files
  - `reports/` - Coverage reports and statistics

**Taxonomy and categories**:
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/taxonomy.json` (74 tags)
- `/Users/cns/httpdocs/cddo/status/specs/002-add-9500-public-services/categories.json` (15 categories)

**Production config**:
- `/Users/cns/httpdocs/cddo/status/config.yaml` (currently 205 services)

### Tool Commands

**DNS enumeration**:
```bash
# Subfinder (fast, multiple sources)
subfinder -d services.gov.uk -o output.txt

# Amass (comprehensive, slow)
amass enum -passive -d gov.uk -o output.txt
```

**Certificate Transparency**:
```bash
# crt.sh API
curl "https://crt.sh/?q=%.services.gov.uk&output=json" | jq -r '.[].name_value' | sort -u
```

**Validation pipeline**:
```bash
# Run scripts in order (from project root):
pnpm exec tsx scripts/normalize-urls.ts <input-file>
pnpm exec tsx scripts/resolve-redirects.ts <normalized-json>
pnpm exec tsx scripts/deduplicate.ts <canonical-json>
pnpm exec tsx scripts/validate-accessibility.ts <unique-json>
pnpm exec tsx scripts/apply-tags.ts <validated-json>
pnpm exec tsx scripts/transform-to-entries.ts <tagged-json>
pnpm exec tsx scripts/generate-yaml.ts <entries-json>
pnpm exec tsx scripts/validate-config.ts <generated-yaml>
pnpm exec tsx scripts/generate-report.ts <entries-json>
```

**Config validation**:
```bash
# Validate config.yaml against JSON Schema
pnpm exec tsx scripts/validate-config.ts config.yaml
```

### Discovery Research Tools

**Web search operators**:
```
site:*.service.gov.uk hmrc OR tax OR vat
site:*.nhs.uk appointment OR booking OR 111
site:*.police.uk report OR crime OR online
inurl:apply site:*.gov.uk
inurl:service site:*.gov.uk
```

**Government directories**:
- GOV.UK services: https://www.gov.uk/browse
- NHS Digital catalog: https://digital.nhs.uk/services
- Police.UK forces: https://www.police.uk/pu/contact-the-police/
- Local councils: https://www.gov.uk/find-local-council
- HMCTS services: https://www.gov.uk/courts-tribunals

**Research documentation**:
- All discovery sources must be documented in research-data/reports/
- Service ownership mapping maintained
- Excluded services tracked with reasons

### Success Metrics

**Discovery metrics**:
- Total services discovered per user story
- Validation success rate (target: 90%+, proven: 95.83%)
- Coverage per department/category
- Discovery method effectiveness (DNS vs web search vs manual)

**Quality metrics**:
- JSON Schema validation errors (target: 0)
- Duplicate services detected
- Tag coverage per service (minimum 2 tags, maximum 10)
- YAML file size (target: <5MB)

**Performance metrics**:
- Validation pipeline time (measured: ~5min per 100 services)
- Discovery time per user story (tracked against estimates)
- Calendar time to completion (Option 2: 3-5 days solo, 1.5-2 days team)

---

## Success Definition

### Option 2 (P1 User Stories) Success Criteria

**Quantitative**:
- ‚úÖ 2500-3800 unique service endpoints discovered and validated
- ‚úÖ 50+ services per major government department (HMRC, DVLA, DWP, Home Office, NHS)
- ‚úÖ All 4 UK health systems represented (NHS England, Scotland, Wales, NI)
- ‚úÖ 100+ emergency service endpoints (police, fire, ambulance)
- ‚úÖ 90%+ validation success rate
- ‚úÖ Zero JSON Schema validation errors
- ‚úÖ Config.yaml file size <5MB
- ‚úÖ All validation scripts operational (9/9)

**Qualitative**:
- ‚úÖ Services organized by meaningful categories (criticality tier, department)
- ‚úÖ Comprehensive tagging using 74-tag taxonomy
- ‚úÖ Inline YAML comments for maintainability
- ‚úÖ Documentation of discovery methodology
- ‚úÖ Coverage reports generated
- ‚úÖ Ready for production deployment

**Process**:
- ‚úÖ All P1 user stories (US1-US3) complete
- ‚úÖ All discovery methods executed (DNS, CT logs, web search, directories)
- ‚úÖ Validation pipeline proven end-to-end
- ‚úÖ Quality gates passed (discovery completeness, validation rate, YAML quality, integration testing)
- ‚úÖ Task tracking updated (tasks.md completion status)
- ‚úÖ Implementation status documented

**Deliverables**:
- ‚úÖ `research-data/government-services.yaml` (validated)
- ‚úÖ `research-data/nhs-services.yaml` (validated)
- ‚úÖ `research-data/emergency-services.yaml` (validated)
- ‚úÖ `config.yaml` merged with new services (validated)
- ‚úÖ Coverage reports for each user story
- ‚úÖ Updated IMPLEMENTATION_STATUS.md
- ‚úÖ Updated tasks.md with completion status
- ‚úÖ Branch ready for PR or merge

---

## Next Immediate Actions

### To Start Option 2 (P1 User Stories):

1. **Choose execution model**:
   - Solo researcher (3-5 days)
   - 3-person team (1.5-2 days)
   - 5-person team (1 day)

2. **Set up tracking**:
   ```bash
   # Create progress tracking file
   touch specs/002-add-9500-public-services/research-data/progress.md
   ```

3. **Begin User Story 1 (Government Services)**:
   ```bash
   # Launch parallel discovery
   cd /Users/cns/httpdocs/cddo/status

   # T020: Subfinder
   subfinder -d services.gov.uk -o specs/002-add-9500-public-services/research-data/discovered/services-gov-uk.txt

   # T021: CT logs
   curl "https://crt.sh/?q=%.services.gov.uk&output=json" | \
     jq -r '.[].name_value' | sort -u > specs/002-add-9500-public-services/research-data/discovered/services-gov-uk-crtsh.txt

   # T022: Amass (background)
   amass enum -passive -d gov.uk -o specs/002-add-9500-public-services/research-data/discovered/gov-uk-amass.txt &

   # T023-T030: Web search discovery (manual research)
   # Use WebSearch tool with operators documented in Discovery Method Guide
   ```

4. **Track progress**:
   - Update tasks.md after each task completion
   - Document time spent vs estimates
   - Update progress.md with discoveries

5. **Quality checkpoints**:
   - After each user story: verify coverage minimums
   - After validation pipeline: review success rates
   - Before integration: manual YAML review
   - Before merge: full quality gate checklist

### To Extend to Option 3 or 4:

After completing Option 2, assess:
- Time spent vs estimates (adjust remaining estimates)
- Validation success rates (identify patterns)
- Discovery method effectiveness (optimize approach)
- Resource availability (continue or pause)

Then proceed with:
- Option 3: Add US4-US7 (35-45 additional hours)
- Option 4: Add US8-US9 (8 additional hours beyond Option 3)

---

## Conclusion

**Current State**: All infrastructure is production-ready. The validation pipeline is proven with 23 services successfully merged into config.yaml. The feature is ready for full-scale data collection.

**Recommended Next Step**: Execute Option 2 (P1 User Stories) to deliver 2500-3800 critical government, NHS, and emergency services within 3-5 days (solo) or 1.5-2 days (team).

**Path Forward**: Option 2 provides high-value delivery with manageable scope. After completion, assess results and optionally extend to Option 3 (additional 35-45 hours) or Option 4 (complete 9500+ target) based on available resources and time.

**Key Success Factors**:
- Parallel discovery execution (saves 50%+ calendar time)
- Automated validation pipeline (proven 5min per 100 services)
- Quality gates at each checkpoint (prevents rework)
- Incremental delivery options (manage risk and scope)
- Comprehensive documentation (supports long-term maintenance)

The foundation is solid. The process is proven. The path is clear. Ready to scale from 23 to 9500+ services.

---

**Document Status**: Complete and ready for execution

**Last Updated**: 2025-10-26

**Version**: 3.0 (Complete implementation guide)
